This Use Case is designed to represent a theoretical "best case" for accuracy, but a "worst case" for efficiency. It serves as a powerful benchmark to demonstrate *why* sophisticated memory architectures are necessary in the first place. By comparing our full system to this baseline, we can make a clear, quantitative argument about the cost-performance trade-offs.

Here is the detailed Use Case Specification for the third experimental run.

---

### **Use Case Specification: Run GoodAI LTM Benchmark with Full-Context Agent**

| **Use Case Name:** | Execute a Single Test from the GoodAI LTM Benchmark (Full-Context Baseline) |
| :--- | :--- |
| **ID:** | UC-03 |
| **Actors:** | Benchmark Runner (Script), **MAS (Full-Context Baseline)**, `FullContextAgent`, **Redis** |
| **Description:** | The system processes a single turn from the GoodAI LTM Benchmark using a naive "infinite context" agent. This baseline appends the entire conversational history to the LLM's context for every turn, simulating a system with a theoretically perfect but practically inefficient memory. It is designed to establish an upper bound for accuracy while highlighting the severe latency and cost problems that our hybrid architecture solves. |
| **Preconditions:** | 1. The infrastructure is deployed. A Redis instance is available on the Orchestrator Node to act as a simple list store for the conversation history. <br> 2. The MAS is instantiated with the "Full-Context" configuration. The `UnifiedMemorySystem` is bypassed entirely. <br> 3. The Agent Wrapper API endpoint is running. |
| **Postconditions:** | 1. The agent's final answer is returned to the Benchmark Runner for scoring. <br> 2. The new conversational turn is appended to the history list in Redis. <br> 3. Instrumentation logs, particularly latency and token counts, are written to the observability store. |

---

| **Step** | **Action Description & Component Interaction** | **Requirements for this Step** |
| :--- | :--- | :--- |
| 1. **Initiation** | The **Benchmark Runner** sends an HTTP request to the Agent Wrapper with the full history and the latest user message. | - Agent Wrapper must expose the same API endpoint (`/run_turn`) as UC-01/UC-02. <br> - Wrapper must correctly parse the benchmark's JSON payload. |
| 2. **Task Delegation** | The Agent Wrapper forwards the request to the `FullContextAgent`. | - The MAS is configured to route all incoming tasks directly to the `FullContextAgent`. |
| 3. **Internal State Retrieval** | The **`FullContextAgent`** performs **no action** to retrieve a structured internal state. Its only "state" is the full, linear conversation history. | - **Architectural Constraint:** The agent's logic is stateless and does not use `PersonalMemoryState`. |
| 4. **Knowledge Retrieval** | The **`FullContextAgent`** performs a simple but massive retrieval: <br> a) It connects to **Redis** on the local Orchestrator Node. <br> b) It retrieves the *entire* conversational history, which is stored as a single, long string or list. | - **Performance:** While the Redis call itself is fast, retrieving and holding a potentially massive string (e.g., 120k+ tokens worth of text) in memory can be resource-intensive. |
| 5. **Synthesis & Response Generation** | The **`FullContextAgent`** performs a naive synthesis: <br> a) It concatenates the entire retrieved history with the latest user message. <br> b) This complete, massive text block is sent as a single prompt to the LLM to generate a response. | - **Architectural Constraint:** This step is intentionally inefficient and costly. It will consume a very large number of tokens for both the prompt and the generation. <br> - **Performance:** The time-to-first-token is expected to be extremely high due to the large prompt size. The system is likely to hit API rate limits or context window limits on longer tests. |
| 6. **Update Working Memory** | The **`FullContextAgent`** performs **no action** to update a structured working memory. | - **Architectural Constraint:** No L1/L2 Operating Memory layer is used. |
| 7. **Asynchronous Consolidation** | This step is **not applicable**. The agent's only memory update is to append the new conversational turn (user message + AI response) back to the single history list in **Redis**. | - **Architectural Constraint:** The system has no concept of a multi-layered memory or knowledge distillation. All information is treated as a single, undifferentiated stream. |
| 8. **Finalization** | The **`FullContextAgent`** returns its final generated text response to the Agent Wrapper, which sends it back to the **Benchmark Runner**. | - The response format must strictly adhere to the schema expected by the benchmark's scoring script. |