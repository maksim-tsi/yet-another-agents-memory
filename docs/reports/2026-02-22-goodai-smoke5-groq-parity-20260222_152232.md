# Report: GoodAI LTM Benchmark (Agent Variant, Groq Routing)

**Date:** 2026-02-22  
**YAAM Commit:** `12dd97b59676fa3689052ec5a7e35bb0f469a483`  
**Benchmark Commit/Version:** `12dd97b59676fa3689052ec5a7e35bb0f469a483`  
**Agent Type:** `full`  
**Agent Variant:** `v1-min-skillwiring`  
**Agent ID:** `mas-full__v1-min-skillwiring`  
**Run Name:** `goodai__smoke5__provider=groq__model=openai-gpt-oss-120b__promotion=disabled__agent=full__v1-min-skillwiring__20260222_152232`  

## 1. Executive Summary

Smoke5 completed successfully with Groq routing. The run produced complete artifacts (master log, turn metrics, run stats, and HTML report). Two notable failures occurred: Prospective Memory scored 0/1 (quote placement error), and Restaurant scored 0.2/1 (rubric mismatch around drink ordering). Other datasets scored 1.0/1.0. Results appear repeatable given stable runtime and clean exit.

## 2. Run Configuration (Reproducibility)

### 2.1 Topology

- Host: MacBook (local)
- Redis: `skz-dev-lv` via SSH tunnel to `localhost:6379`
- Postgres: via `POSTGRES_URL` from root `.env` (redacted)
- API Wall: `uvicorn` on `http://127.0.0.1:8081`
- GoodAI runner venv: `benchmarks/goodai-ltm-benchmark/.venv`

### 2.2 Endpoints

- `AGENT_URL`: `http://127.0.0.1:8081/v1/chat/completions`
- `YAAM /health`: `http://127.0.0.1:8081/health`

### 2.3 Environment Variables (YAAM)

| Variable | Value |
|---|---|
| `MAS_AGENT_TYPE` | `full` |
| `MAS_AGENT_VARIANT` | `v1-min-skillwiring` |
| `MAS_MODEL` | `openai/gpt-oss-120b` |
| `MAS_PROMOTION_MODE` | `disabled` |
| `MAS_PROMOTION_TIMEOUT_S` | *(default 30s; unused because promotion disabled)* |
| `MAS_FACT_EXTRACTOR_MODEL` | *(defaulted to `MAS_MODEL`)* |
| `MAS_TOPIC_SEGMENTER_MODEL` | *(defaulted to `MAS_MODEL`)* |
| `MAS_MIN_CIAR` | *(default)* |
| `MAS_L1_WINDOW` | *(default)* |
| `MAS_L1_TTL_HOURS` | *(default)* |
| `REDIS_URL` | `redis://localhost:6379` |
| `POSTGRES_URL` | *(redacted host ok)* |

### 2.4 Provider Configuration (Groq)

- Provider(s) enabled: `groq`
- Groq model: `openai/gpt-oss-120b`
- Promotion: `disabled` (Smoke5 default; `skip_l1_write` remained true)

### 2.5 LLM-Engine Routing (Critical for Attribution)

Promotion engines were not exercised because `skip_l1_write=true` for API Wall requests. FactExtractor and TopicSegmenter therefore did not run during this benchmark. Their default models are documented above for parity tracking.

## 3. Results

### 3.1 Aggregate Scores

| Dataset | Metric | Score | Notes |
|---|---:|---:|---|
| Instruction Recall | accuracy | 1.0 | Pass |
| Prospective Memory | accuracy | 0.0 | Quote placement error |
| Restaurant | accuracy | 0.2 | Rubric penalized drink ordering |
| Spy Meeting | accuracy | 1.0 | Pass |
| Trigger Response | accuracy | 1.0 | Pass |

### 3.2 Performance

| Metric | Value |
|---|---:|
| Turns processed | 100 |
| Duration (s) | 171.77 |
| Total tokens | 29,572 |
| Agent tokens | 4,673 |
| Median `llm_ms` | 3,392.36 |
| P95 `llm_ms` | 30,852.76 |
| P99 `llm_ms` | 30,898.92 |
| Median `storage_ms` | 70.94 |
| P95 `storage_ms` | 78.94 |
| P99 `storage_ms` | 81.46 |

### 3.3 Error Taxonomy (Observed)

| Category | Count | Example symptom | Likely cause |
|---|---:|---|---|
| Reasoning failure (retrieval-reasoning gap) | 1 | Prospective Memory quote appended at wrong position | Instruction-following policy ordering |
| Evaluation rubric mismatch | 1 | Restaurant task penalized drink order | Dataset rubric expectation mismatch |
| Infrastructure/network | 0 | n/a | n/a |

## 4. Visibility/Transparency Matrix (Artifact-Based)

| Component | What to verify | Where to observe | Pass/Fail | Notes |
|---|---|---|---|---|
| Session isolation | prefixed session IDs | `master_log.jsonl` metadata `yaam_session_id` | Pass | Prefix visible |
| LLM traceability | provider+model per turn | `master_log.jsonl` metadata `llm_provider`, `llm_model` | Pass | Groq attribution |
| Timing transparency | storage vs LLM timings | `master_log.jsonl`, `turn_metrics.jsonl` | Pass | `llm_ms`, `storage_ms` present |
| Memory writes | L1/L2 write behavior | response metadata `skip_l1_write` | Pass (expected) | Writes suppressed in Smoke5 |
| Report generation | HTML present | `data/reports/` | Pass | HTML generated |

## 5. Artifacts and Logs

- Raw benchmark outputs: `benchmarks/goodai-ltm-benchmark/data/tests/goodai__smoke5__provider=groq__model=openai-gpt-oss-120b__promotion=disabled__agent=full__v1-min-skillwiring__20260222_152232/results/RemoteMASAgentSession - remote/`
- GoodAI console log: `benchmarks/goodai-ltm-benchmark/data/tests/goodai__smoke5__provider=groq__model=openai-gpt-oss-120b__promotion=disabled__agent=full__v1-min-skillwiring__20260222_152232/results/RemoteMASAgentSession - remote/run_console.log`
- GoodAI master log: `benchmarks/goodai-ltm-benchmark/data/tests/goodai__smoke5__provider=groq__model=openai-gpt-oss-120b__promotion=disabled__agent=full__v1-min-skillwiring__20260222_152232/results/RemoteMASAgentSession - remote/master_log.jsonl`
- GoodAI per-turn metrics: `benchmarks/goodai-ltm-benchmark/data/tests/goodai__smoke5__provider=groq__model=openai-gpt-oss-120b__promotion=disabled__agent=full__v1-min-skillwiring__20260222_152232/results/RemoteMASAgentSession - remote/turn_metrics.jsonl`
- GoodAI run stats: `benchmarks/goodai-ltm-benchmark/data/tests/goodai__smoke5__provider=groq__model=openai-gpt-oss-120b__promotion=disabled__agent=full__v1-min-skillwiring__20260222_152232/results/RemoteMASAgentSession - remote/runstats.json`
- Per-dataset JSON: `.../Instruction Recall/0_0.json`, `.../Prospective Memory/0_0.json`, `.../Restaurant/0_0.json`, `.../Spy Meeting/0_0.json`, `.../Trigger Response/0_0.json`
- YAAM rate limiter JSONL: `logs/rate_limiter_full_v1-min-skillwiring_20260222_131911.jsonl`
- HTML report: `benchmarks/goodai-ltm-benchmark/data/reports/2026-02-22 15_29_01 - Detailed Report - goodai__smoke5__provider=groq__model=openai-gpt-oss-120b__promotion=disabled__agent=full__v1-min-skillwiring__20260222_152232 - RemoteMASAgentSession - remote.html`

## 6. Proposed Next Steps

1. **Parity replication:** Run identical Smoke5 configurations for Gemini and Mistral using the same `MAS_PROMOTION_MODE=disabled` and the run-name convention in the experiment matrix.
2. **Promotion validation:** Execute the memory-engine validation runs with `skip_l1_write=false` and `MAS_PROMOTION_MODE=async` then `barrier`, and confirm promotion metadata is visible in artifacts.
3. **Failure analysis:** Inspect `master_log.jsonl` entries for Prospective Memory and Restaurant to determine whether prompt-instruction ordering or rubric mismatch is responsible, and assess whether policy-layer adjustments are needed.
4. **Artifact completeness check:** Confirm that per-turn metadata (`llm_provider`, `llm_model`, `context.*`, `client_session_id`, `yaam_session_id`, `llm_ms`, `storage_ms`) are consistently present in `master_log.jsonl` and `turn_metrics.jsonl`.
