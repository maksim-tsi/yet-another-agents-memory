# Lessons Learned Register

This register captures recurring issues surfaced during development and the mitigations that resolve them. Entries should be concise, structured, and updated immediately after an incident is resolved.

## Usage Guidelines
- Document only project-specific incidents that produced unexpected failures or workflow friction.
- Prefer objective wording; avoid speculation unless clearly marked as a hypothesis.
- Include enough context (environment, command, files) so another engineer can reproduce or validate the scenario.
- Link to supporting artifacts such as logs, pull requests, or chat transcripts when available.

## Entry Template
Use the following table format for all new entries. Update the `Status` column as mitigations are adopted or superseded.

| Date       | Incident ID           | Environment        | Symptom                                                                 | Root Cause                                                                                   | Mitigation                                                                                                    | Status   | References |
|------------|-----------------------|--------------------|-------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------|----------|------------|
| YYYY-MM-DD | LL-YYYYMMDD-XX        | Host + OS details | Brief error description (command/test/etc.)                             | Concise explanation of why the issue occurred                                                | Specific steps, scripts, or instruction updates that prevent recurrence                                      | Active   | Links      |

## Entries

| Date       | Incident ID            | Environment                        | Symptom                                                                                               | Root Cause                                                                                                    | Mitigation                                                                                                                                                   | Status   | References |
|------------|------------------------|------------------------------------|-------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------|----------|------------|
| 2026-01-03 | LL-20260103-01         | Remote Ubuntu VM + Qdrant          | Test `test_l2_to_l3_consolidation_with_episode_clustering` fails with "No episodes found in Qdrant" despite successful store (status=COMPLETED). Test passed after collection recreation but failed on subsequent runs with accumulated data. | Qdrant `search()` is **vector-similarity-first**: finds N most similar vectors, THEN applies filters. Test used dummy query vector `[0.1]*768` which has ~0 similarity to real Gemini embeddings. Our session's point wasn't in top-10 by similarity, so filter returned nothing. Empty collection worked because our point was the only option. | 1. Added `scroll()` method to `QdrantAdapter` for pure filter-based retrieval (no vector similarity). 2. Changed test to use `scroll()` instead of `search()` for session-based queries. 3. Use `search()` only for semantic similarity queries; use `scroll()` for metadata-based retrieval. | Adopted  | [docs/reports/qdrant-scroll-vs-search-debugging-2026-01-03.md](reports/qdrant-scroll-vs-search-debugging-2026-01-03.md) |
| 2025-12-29 | LL-20251229-01         | Remote Ubuntu VM + Gemini API      | "Unterminated string starting at: line 7 column 9 (char 505)" - JSON parsing failures in FactExtractor/TopicSegmenter with harmony-format models | LLM concatenated system+user prompts without structured output enforcement. Groq's openai/gpt-oss-120b outputs harmony format (analysis+final channels) incompatible with simple JSON.loads(). No model-to-provider routing caused Gemini models to be sent to Groq provider. | 1. Use native `types.Schema` structured output with `response_mime_type="application/json"`. 2. Separate `system_instruction` parameter. 3. Add `MODEL_ROUTING` map in LLMClient to route models to correct providers. 4. Switch to gemini-3-flash-preview as primary model (ADR-006). Created schema definitions in `src/memory/schemas/` with FACT_EXTRACTION_SCHEMA and TOPIC_SEGMENTATION_SCHEMA. | Adopted  | DEVLOG 2025-12-29, examples/gemini_structured_output_test.md, tests/test_fact_extraction_with_real_data.py |
| 2025-11-15 | LL-20251115-01         | Local macOS checkout (`dev` branch) | `run_in_terminal` reported "no output" after commands with `> /tmp/... && cat /tmp/...` chaining. | Main command exited non-zero (missing binary), so the `&& cat` step never executed, hiding captured stderr. | Always capture output to `/tmp/*.out` but follow with `; cat /tmp/*.out` (or separate `cat` command) so logs surface even when the primary command fails. Update instructions to note this pattern. | Adopted  | Session log 2025-11-15 |

