# file: requirements.txt
#
# Python Version: 3.13.5
# Date: September 14, 2025
#
# This file contains the Python dependencies for the Hybrid Memory System project.
# To install, run: pip install -r requirements.txt
#
# SYSTEM DEPENDENCIES (install before pip install):
# - PostgreSQL client tools (psql): Required for database setup and migrations
#   Ubuntu/Debian: sudo apt install -y postgresql-client
#   macOS: brew install postgresql
#   Verify: psql --version

# --- Core Frameworks & Data Validation ---
pydantic==2.8.2          # For data validation, settings management, and defining our data schemas.

# --- Operating Memory Layer (Redis) ---
redis==5.0.7             # The official Python client for Redis.

# PostgreSQL Async Driver
# Note: asyncpg requires compilation. If you encounter build errors:
# Option 1 (Recommended): Use psycopg[binary] instead
# Option 2: Ensure build tools are installed: apt-get install build-essential python3-dev
# For Python 3.13, we use psycopg with binary wheels (works with Python 3.13)
psycopg[binary]>=3.2.0  # PostgreSQL adapter with binary wheels (works with Python 3.13)
psycopg_pool==3.2.7     # Async connection pooling layer used by PostgresAdapter

# --- Persistent Knowledge Layer (Specialized Databases) ---

# Vector Store Client
qdrant-client==1.9.2     # The official Python client for the Qdrant vector database.
sentence-transformers==3.0.1 # Used for creating high-quality sentence/text embeddings.
# Note: sentence-transformers will pull in PyTorch, transformers, etc.

# Graph Store Client
neo4j==5.22.0            # The official Python driver for the Neo4j graph database.

# Search Store Client
meilisearch==0.28.0      # The official Python client for the Meilisearch engine.

# --- LLM Providers (ADR-006: Free-Tier Multi-Provider Strategy) ---

# Google Gemini (Primary Provider)
google-genai==1.2.0      # Official Google Generative AI SDK for Gemini models
                        # Supports: gemini-2.5-flash, gemini-2.0-flash, gemini-2.5-flash-lite
                        # Rate limits: 10-15 RPM, 250k-1M TPM
                        # Documentation: https://ai.google.dev/

# Groq (Ultra-Fast Inference Provider)
groq==0.33.0             # Official Groq SDK for ultra-fast LPU inference
                        # Supports: llama-3.1-8b-instant, openai/gpt-oss-120b, mixtral, gemma2
                        # Rate limits: 30 RPM, 20k-200k TPM, ~250-800 tokens/sec
                        # Documentation: https://console.groq.com/docs

# Mistral AI (Complex Reasoning Provider)
mistralai==1.0.3         # Official Mistral AI SDK for advanced reasoning models
                        # Supports: mistral-large-latest, mistral-small-latest
                        # Rate limits: 60 RPM (1 RPS), fair use policy
                        # Documentation: https://docs.mistral.ai/

# --- Development & Testing Utilities ---
fakeredis==2.23.1        # A mock Redis client, useful for running tests without a live Redis server.
# Note: For the __main__ demo block in memory_system.py to run self-contained.

# --- Environment Management ---
python-dotenv==1.2.1     # Loads provider keys and infra settings for scripts/tests